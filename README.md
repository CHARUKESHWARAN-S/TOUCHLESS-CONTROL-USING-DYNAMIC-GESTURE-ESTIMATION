# ğŸ– Touchless Control using Dynamic Gesture Estimation

An AI-powered system that enables *hands-free computer interaction* through *real-time dynamic hand gesture recognition*.  
Built using *MediaPipe, **OpenCV, and **Python, it detects and interprets gestures to perform actions like **volume adjustment, **cursor control, and **media playback* â€” all without physical touch.

---

## ğŸš€ Features
- Real-time hand tracking using *MediaPipe*
- Dynamic gesture recognition for multiple actions
- Smooth and responsive gesture-to-action mapping
- Works with any standard webcam
- Cross-platform support (Windows/Linux)

---

## ğŸ§  Tech Stack
- *Language:* Python  
- *Libraries:* MediaPipe, OpenCV, NumPy, TensorFlow, PyAutoGUI  
- *Model:* LSTM / CNN-based gesture sequence recognition  
- *Interface:* Command-line / Visual overlay feedback  

---

## âš™ System Workflow
1. Capture hand movements via webcam  
2. Extract 21 hand landmarks using MediaPipe  
3. Process temporal frames for gesture patterns  
4. Recognize gestures using trained model  
5. Map recognized gestures to system-level actions  

---

## ğŸ“‚ Project Structure
ğŸ“¦ touchless-control
â”£ ğŸ“œ requirements.txt # Dependencies
â”£ ğŸ“œ LICENSE # MIT License
â”— ğŸ“œ README.md # Project description



---

## ğŸ§© Installation
```bash
git clone https://github.com/CHARUKESHWARAN-S/TOUCHLESS-CONTROL-USING-DYNAMIC-GESTURE-ESTIMATION.git
cd touchless-control
pip install -r requirements.txt
â–¶ Usage
bash
Copy code
python main.py
Perform gestures like:

âœ‹ Swipe Left / Right â€“ navigate

ğŸ‘Š Fist Hold â€“ pause/play media

â˜ Move Hand â€“ control cursor

ğŸ¤š Open Palm Up/Down â€“ volume up/down

